{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output, display\n",
    "from PIL import Image\n",
    "\n",
    "from sam2.build_sam import build_sam2_object_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68bf93105a7b2da1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self,\n",
    "                 video_width,\n",
    "                 video_height,\n",
    "                 ):\n",
    "        \n",
    "        self.video_width = video_width\n",
    "        self.video_height = video_height\n",
    "\n",
    "    def resize_mask(self, mask):\n",
    "        mask = torch.tensor(mask, device='cpu')\n",
    "        mask = torch.nn.functional.interpolate(mask,\n",
    "                                               size=(self.video_height, self.video_width),\n",
    "                                               mode=\"bilinear\",\n",
    "                                               align_corners=False,\n",
    "                                               )\n",
    "        \n",
    "        return mask\n",
    "\n",
    "    def add_frame(self, frame, mask):\n",
    "        frame = frame.copy()\n",
    "        frame = cv2.resize(frame, (self.video_width, self.video_height))\n",
    "        \n",
    "        mask = self.resize_mask(mask=mask)\n",
    "        mask = (mask > 0.0).numpy()\n",
    "        \n",
    "        for i in range(mask.shape[0]):\n",
    "            obj_mask = mask[i, 0, :, :]\n",
    "            frame[obj_mask] = [255, 105, 180]\n",
    "                \n",
    "        rgb_frame = Image.fromarray(frame)\n",
    "        clear_output(wait=True)\n",
    "        display(rgb_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb1780f6714552fd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Check if the file already exists\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(VIDEO_STREAM):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# If the file doesn't exist, download it\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlretrieve(url, VIDEO_STREAM)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVIDEO_STREAM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[0;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m block \u001b[38;5;241m:=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(bs):\n\u001b[0;32m    269\u001b[0m     read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[0;32m    270\u001b[0m     tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\http\\client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Download Example Video\n",
    "VIDEO_STREAM = \"./TUD-Stadtmitte-raw.webm\"\n",
    "url = 'https://motchallenge.net/sequenceVideos/TUD-Stadtmitte-raw.webm'\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(VIDEO_STREAM):\n",
    "    # If the file doesn't exist, download it\n",
    "    urllib.request.urlretrieve(url, VIDEO_STREAM)\n",
    "    print(f\"Downloading {VIDEO_STREAM}...\")\n",
    "else:\n",
    "    print(f\"File {VIDEO_STREAM} already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d82f908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot open femtobolt camera at index 0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "CAM_INDEX = 0\n",
    "video_stream = cv2.VideoCapture(CAM_INDEX, cv2.CAP_V4L2)\n",
    "\n",
    "if not video_stream.isOpened():\n",
    "    print(f\"Cannot open femtobolt camera at index {CAM_INDEX}\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"Successfully opened femtobolt camera at index {CAM_INDEX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb66ca244d0f0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set SAM2 Configuration\n",
    "NUM_OBJECTS = 2\n",
    "YOLO_CHECKPOINT_FILEPATH = \"yolov8x-seg.pt\"\n",
    "SAM_CHECKPOINT_FILEPATH = \"../checkpoints/sam2.1_hiera_base_plus.pt\"\n",
    "SAM_CONFIG_FILEPATH = \"./configs/samurai/sam2.1_hiera_b+.yaml\"\n",
    "OUTPUT_PATH = VIDEO_STREAM + \"_segmented.mp4\"\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909a1eff131e1e1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open Video Stream\n",
    "video_stream = cv2.VideoCapture(VIDEO_STREAM)\n",
    "\n",
    "video_height = int(video_stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "video_width = int(video_stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "# For real-time visualization\n",
    "visualizer = Visualizer(video_width=video_width,\n",
    "                        video_height=video_height\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4394d77e3b63645",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sam = build_sam2_object_tracker(num_objects=NUM_OBJECTS,\n",
    "                                config_file=SAM_CONFIG_FILEPATH,\n",
    "                                ckpt_path=SAM_CHECKPOINT_FILEPATH,\n",
    "                                device=DEVICE,\n",
    "                                verbose=False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2d1a1e04cfa1a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "available_slots = np.inf\n",
    "\n",
    "first_frame = True\n",
    "with torch.inference_mode(), torch.autocast('cuda:0', dtype=torch.bfloat16):\n",
    "    while video_stream.isOpened():\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Get next frame\n",
    "        ret, frame = video_stream.read()\n",
    "        \n",
    "        # Exit if no frames remaining\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame from BGR to RGB\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Simulate detection on first frame\n",
    "        if first_frame:\n",
    "            bbox = np.array([[[172, 92], [254, 325]], \n",
    "                             [[334, 76],  [439, 329]]]\n",
    "                            )\n",
    "            \n",
    "            sam_out = sam.track_new_object(img=img,\n",
    "                                           box=bbox\n",
    "                                           )\n",
    "            \n",
    "            first_frame = False\n",
    "            \n",
    "        else:\n",
    "            sam_out = sam.track_all_objects(img=img)\n",
    "            \n",
    "        visualizer.add_frame(frame=frame, mask=sam_out['pred_masks'])\n",
    "        \n",
    "video_stream.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a4fd8bafcf9b4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human_detection",
   "language": "python",
   "name": "human_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
